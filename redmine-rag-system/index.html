<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Redmine RAG system - Zoltán's Blog</title><meta name=description content='It was so tempting to give it the title "Oops, I did it again."'><meta name=author content="map[email:zoltan.balogh@suse.com github:bzoltan1 linkedin:zbalogh name:Zoltán Balogh]"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Zoltán\u0027s Blog","url":"https:\/\/bzoltan1.github.io\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/bzoltan1.github.io\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/bzoltan1.github.io\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/bzoltan1.github.io\/redmine-rag-system\/","name":"Redmine rag system"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Zoltán Balogh"},"headline":"Redmine RAG system","description":"The Goal The goal was to extract all issues from a Redmine instance, anonymize the data, and build a local RAG system for semantic search and Q\u0026amp;A.\nJust like with the previous experiment with Bugzilla it started with data extraction. I planned to make a simple bulk download via Redmine API. Then came the first problem. Redmine\u0026rsquo;s API doesn\u0026rsquo;t return journal entries (comments) when using the project-level endpoint, even with the include=journals parameter. I tried out different ways but nothing worked. The solution was, after all, to change the strategy and fetch each issue individually via \/issues\/{id}.json. This was much slower but guaranteed complete data including all comments.\n","inLanguage":"en","wordCount":1541,"datePublished":"2025-12-05T05:00:00\u002b02:00","dateModified":"2025-12-05T05:00:00\u002b02:00","image":"https:\/\/bzoltan1.github.io\/avatar.png","keywords":["Redmine, LLM, Chroma DB, Ollama"],"mainEntityOfPage":"https:\/\/bzoltan1.github.io\/redmine-rag-system\/","publisher":{"@type":"Organization","name":"https:\/\/bzoltan1.github.io\/","logo":{"@type":"ImageObject","url":"https:\/\/bzoltan1.github.io\/avatar.png","height":60,"width":60}}}</script><meta property="og:title" content="Redmine RAG system"><meta property="og:description" content='It was so tempting to give it the title "Oops, I did it again."'><meta property="og:image" content="https://bzoltan1.github.io/avatar.png"><meta property="og:url" content="https://bzoltan1.github.io/redmine-rag-system/"><meta property="og:type" content="website"><meta property="og:site_name" content="Zoltán's Blog"><meta name=twitter:title content="Redmine RAG system"><meta name=twitter:description content='It was so tempting to give it the title "Oops, I did it again."'><meta name=twitter:image content="https://bzoltan1.github.io/avatar.png"><meta name=twitter:card content="summary_large_image"><link href=https://bzoltan1.github.io/avatar.png rel=icon type=image/x-icon><meta name=generator content="Hugo 0.147.5"><link rel=alternate href=https://bzoltan1.github.io/index.xml type=application/rss+xml title="Zoltán's Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://bzoltan1.github.io/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://bzoltan1.github.io/css/syntax.css><link rel=stylesheet href=https://bzoltan1.github.io/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=https://bzoltan1.github.io/>Zoltán's Blog</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li><a title=Blog href=https://bzoltan1.github.io/>Blog</a></li><li><a title=Tags href=https://bzoltan1.github.io/tags>Tags</a></li><li><a title=Home href=https://bzoltan1.github.io/>Home</a></li><li><a title=About href=https://bzoltan1.github.io/about>About</a></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title="Zoltán's Blog" href=https://bzoltan1.github.io/><img class=avatar-img src=https://bzoltan1.github.io/avatar.png alt="Zoltán's Blog"></a></div></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Redmine RAG system</h1><h2 class=post-subheading>It was so tempting to give it the title "Oops, I did it again."</h2><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on December 5, 2025
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Zoltán Balogh</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><h3 id=the-goal>The Goal</h3><p>The goal was to extract all issues from a Redmine instance, anonymize the data, and build a local RAG system for semantic search and Q&amp;A.</p><p>Just like with the previous experiment with Bugzilla it started with data extraction. I planned to make a simple bulk download via Redmine API. Then came the first problem. Redmine&rsquo;s API doesn&rsquo;t return journal entries (comments) when using the project-level endpoint, even with the include=journals parameter. I tried out different ways but nothing worked. The solution was, after all, to change the strategy and fetch each issue individually via /issues/{id}.json. This was much slower but guaranteed complete data including all comments.</p><p>All I needed to be careful about was being graceful with the server, so I slept 2–5 seconds between API requests.</p><h3 id=downloading-the-data>Downloading the data</h3><p>An important detail of this phase was that because I did not trust the stability of the API and my network, I wanted to build in a checkpoint system to track progress, retry logic in case something failed (3 attempts per issue), and save after every 50 issues to enable resume on failure. Here is the script: <a href=https://github.com/bzoltan1/Redmine-RAG/blob/main/download_redmine.py>download_redmine.py</a>
It may not be so exciting to see, but this is how it looked in action:</p><pre tabindex=0><code>~/Redmine-RAG $ python3.11 download_redmine.py
$ python3.11 download_redmine.py 
✓ Completed 2513 issues for &#39;virtualization&#39;
✓ Completed 1920 issues for &#39;performance&#39;
✓ Completed 583 issues for &#39;qesecurity&#39;
✓ Completed 1662 issues for &#39;qe-kernel&#39;
✓ Completed 561 issues for &#39;qam&#39;
✓ Completed 2312 issues for &#39;qe-yast&#39;
✓ Completed 12987 issues for &#39;openqatests&#39;
✓ Completed 2150 issues for &#39;openqa-infrastructure&#39;
✓ Completed 3300 issues for &#39;containers&#39;

Total issues downloaded: 27988
✓ Merged 27988 issues into redmine_master_dataset.json
Next step: Preprocess and chunk &#39;redmine_master_dataset.json&#39; for RAG.
</code></pre><p>I scheduled the downloading process for 2–3 days. During this time I encountered one massive DNS resolution failure. Around 700+ issues failed with “Failed to resolve &lsquo;…&rsquo;” errors. I do not know if it was caused by network instability or if my request rate was still too aggressive. Anyhow, thanks to the success/failure tracking in checkpoints and the retry/resume mechanism I successfully downloaded all 27,975 issues with complete journal data across all the projects I was interested in.<a href=https://github.com/bzoltan1/Redmine-RAG/blob/main/download_individual_redmine_issues.py>download_individual_redmine_issues.py</a></p><p>This is how it works on the second round when I downloaded the journals for those issues what failed on the first round:</p><pre tabindex=0><code>~/Redmine-RAG $ python3.11 download_individual_redmine_issues.py

======================================================================
Redmine Journal Enrichment Script (with Retry Logic)
======================================================================

✓ Loaded 27979 issues from redmine_master_dataset.json
✓ Loaded checkpoint: 27966 successful, 13 failed out of 27979 total

⟳ Resuming from checkpoint
   - 27966 issues already successful
   - 13 issues need retry

======================================================================
Starting Journal Enrichment Process
======================================================================
Total issues to process: 27979
Already successful: 27966
To retry: 13
Fresh attempts needed: 0
Rate: 1 request every 1.0 seconds
Estimated time: ~0.2 minutes
======================================================================

[5662/27979] Retrying issue #129166 (attempt 2/3)... ✓ 10 journal(s)
[7094/27979] Retrying issue #59801 (attempt 2/3)... ○ No journals
[7385/27979] Retrying issue #62729 (attempt 2/3)... ✓ 11 journal(s)
[7386/27979] Retrying issue #62741 (attempt 2/3)... ✓ 8 journal(s)
[7387/27979] Retrying issue #63256 (attempt 2/3)... ✓ 3 journal(s)
[7388/27979] Retrying issue #63328 (attempt 2/3)... ✓ 5 journal(s)
[7389/27979] Retrying issue #63331 (attempt 2/3)... ✓ 7 journal(s)
[7390/27979] Retrying issue #63655 (attempt 2/3)... ✓ 6 journal(s)
[11549/27979] Retrying issue #29086 (attempt 2/3)... ✓ 5 journal(s)
[16060/27979] Retrying issue #64054 (attempt 2/3)... ✓ 3 journal(s)
[20770/27979] Retrying issue #133517 (attempt 2/3)... ✓ 2 journal(s)
[20771/27979] Retrying issue #133529 (attempt 2/3)... ✓ 7 journal(s)
[27700/27979] Retrying issue #187119 (attempt 2/3)... ✓ 2 journal(s)

--- Progress Checkpoint ---
Successful: 27979/27979 (100.0%)
With journals: 12 | Without: 1
Currently failing: 0 issues
Max retries exhausted: 0 issues
Elapsed: 0.3 min
---------------------------

✓ Enriched data saved to redmine_master_dataset_with_journals.json
✓ Checkpoint file removed (all issues processed successfully)

======================================================================
Journal Enrichment Run Complete!
======================================================================
Successfully enriched: 27979/27979 (100.0%)
  - With journals: 12
  - Without journals: 1
Still failing: 0 issues (will retry on next run)
Max retries exhausted: 0 issues (kept original data)
Run time: 0.3 minutes
======================================================================


======================================================================
Journal Coverage Analysis
======================================================================
Total issues: 27979
Issues with journals: 12 (0.0%)
Issues without journals: 27967 (100.0%)
Total journals fetched: 69
Average journals per issue: 0.00

Journal count distribution:
  0 journal(s): 27967 issues (100.0%)
  2 journal(s): 2 issues (0.0%)
  3 journal(s): 2 issues (0.0%)
  5 journal(s): 2 issues (0.0%)
  6 journal(s): 1 issues (0.0%)
  7 journal(s): 2 issues (0.0%)
  8 journal(s): 1 issues (0.0%)
  10 journal(s): 1 issues (0.0%)
  11 journal(s): 1 issues (0.0%)
======================================================================

✓ Run complete! Enriched data saved to: redmine_master_dataset_with_journals.json
</code></pre><h3 id=data-anonymization>Data Anonymization</h3><p>A funny detail is that whoever I talked to about my project felt the instant urge to remind me of the importance of data privacy. I felt like when I was ten years old and my grandma told me to wear warm clothes when it is cold outside. Naturally I considered the anonymizing step important. I made a simple script <a href=https://github.com/bzoltan1/Redmine-RAG/blob/main/redmine_master_dataset_anonymizer.py>redmine_master_dataset_anonymizer.py</a>to remove all real usernames before building the RAG system. The script was anonymizing the Issue authors, Assigned users, Journal/comment authors, and Watchers. The rest of the data was safe to store, process, and play with.
The anonymized proof is here that I did it :)</p><pre tabindex=0><code>~/Redmine-RAG $ python3.11 redmine_master_dataset_anonymizer.py

======================================================================
Redmine Dataset Anonymization
======================================================================

Loaded 27979 issues. Anonymizing user data...
  Processed 1000/27979 issues
  [...]
  Processed 27979/27979 issues

✓ Anonymized dataset saved: redmine_master_dataset_anonymized.json
✓ User mapping saved: user_anonymization_mapping.json

======================================================================
Anonymization Complete!
Total issues: 27979
Unique users anonymized: 266

======================================================================
Verification
======================================================================

Original issues: 27979
Anonymized issues: 27979

Sample Author:
  Original: XXX
  Anonymized: User_00XXX

✓ Anonymization verified successfully

Ready for RAG system!
Use the file: redmine_master_dataset_anonymized.json
</code></pre><h3 id=built-in-vs-external-embeddings-in-chromadb>Built-in vs. External Embeddings in ChromaDB</h3><p>When I started experimenting with Redmine issue retrieval, one of the first architectural choices was how to generate embeddings. Should I let ChromaDB handle embeddings internally (built-in embeddings), or embed everything ourselves before ingestion (e.g., using Ollama, nomic-embed-text, mxbai-embed-large, etc.)? Surprisingly, the difference turned out to be significant, both in control and in debugging effort.</p><h2 id=without-embeddings>Without embeddings</h2><p>In this case the script ingests the Redmine issues into ChromaDB without generating embeddings at ingest time. We store only the documents created from the JSON records directly and some metadata. Chroma then generates embeddings on demand at query time using its built-in default embedding model (usually all-MiniLM-L6-v2). This is a fairly simple solution that makes the ingestion fast. The downside is that semantic querying will be slower and less accurate. In short, it is good for quick testing and keyword-style search. It is still a smart solution but more like a glorious and expensive search engine.</p><h2 id=embeddings-with-ollama-sdk>Embeddings with Ollama SDK</h2><p>In this case we ingest the Redmine issues into ChromaDB with embeddings computed using Ollama before being stored. I tried various models starting with nomic-embed-text and also qwen3-embedding and mxbai, but I have not done enough testing to say anything credible about the differences. Using an Ollama embedding model will store not only the documents and the metadata but also the embeddings (vectors). This enables better semantic search quality. The ingestion is slow but the queries will be faster because vectors already exist. In short, embeddings with the Ollama SDK give full semantic ingestion with high-quality embeddings stored up front. This is ideal for production-level semantic search.</p><p><a href=https://github.com/bzoltan1/Redmine-RAG/blob/main/ingest_to_chromadb-embed.py>ingest_to_chromadb-embed.py</a></p><pre tabindex=0><code>$ python3.11 ingest_to_chromadb-embed-qwen3-embedding.py

======================================================================
Redmine -&gt; ChromaDB ingestion WITH embeddings (Ollama SDK)
======================================================================

Loading redmine_master_dataset_anonymized.json...
✓ Loaded 27975 issues

Initializing embedding model: nomic-embed-text (Ollama SDK)
✓ Embedding function ready

Initializing ChromaDB at: ./chroma_db
✓ Created collection &#39;redmine_issues&#39; with embeddings

Processing issues (batch size: 50)...

  ✓ Progress: 50/27975 (0.2%)
  ✓ Progress: 100/27975 (0.4%)
  [...]
  ✓ Progress: 27950/27975 (99.9%)
  ✓ Progress: 27975/27975 (100.0%)

======================================================================
Ingestion complete with embeddings
======================================================================
✓ Collection contains 27975 documents

✓ ChromaDB ready for semantic search!
</code></pre><h3 id=query-cli-or-as-grownups-call-the-frontend>Query CLI or as grownups call the frontend</h3><p>Finally I made a tiny script as a semantic search tool for your Redmine-in-ChromaDB setup. After all issues are embedded and stored, this script lets you search them using natural language.</p><p>It connects to the local ChromaDB directory, loads the selected collection, and uses the same Ollama embedding model (e.g., nomic-embed-text or mxbai-embed-large) to embed your query text. Then it performs a similarity search against all stored Redmine issue vectors and returns the closest matches. The result list shows the document ID, similarity score, and a snippet of the stored issue text, giving you a fast, offline, vector-based search engine for historical Redmine data.
It is important to note here that for consistent and meaningful queries, the same embedding model must be used for both ingesting and querying.</p><h3 id=conclusion>Conclusion</h3><p>During this year&rsquo;s Hackweek I built a complete RAG pipeline from API extraction to semantic search. The checkpoint system and retry logic were essential for reliability. ChromaDB + Ollama provide a solid local-first RAG stack without external dependencies or API costs. I dumped the code to here: <a href=https://github.com/bzoltan1/Redmine-RAG>https://github.com/bzoltan1/Redmine-RAG</a></p><p>And the most important question: how does it work? I do not know yet. It needs to be used first with real questions. For this project I focused on building the pipeline.</p><p>My fundamental worry about this architecture and project in general is that the RAG system with a good LLM frontend is as smart as the data we built the database with. If the Redmine issues do not have smart comments, smart descriptions, and smart resolutions then the RAG system will be flat and stupid.</p><div class=blog-tags><a href=https://bzoltan1.github.io/tags/redmine/>Redmine</a>&nbsp;
<a href=https://bzoltan1.github.io/tags/llm/>LLM</a>&nbsp;
<a href=https://bzoltan1.github.io/tags/chroma-db/>Chroma DB</a>&nbsp;
<a href=https://bzoltan1.github.io/tags/ollama/>Ollama</a>&nbsp;</div></article><ul class="pager blog-pager"><li class=previous><a href=https://bzoltan1.github.io/i-want-to-have-a-hot-shower/ data-toggle=tooltip data-placement=top title="I want to have a hot shower">&larr; Previous Post</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href=mailto:zoltan.balogh@suse.com title="Email me"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://github.com/bzoltan1 title=GitHub><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://linkedin.com/in/zbalogh title=LinkedIn><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">Zoltán Balogh
&nbsp;&bull;&nbsp;&copy;
2025
&nbsp;&bull;&nbsp;
<a href=https://bzoltan1.github.io/>Zoltán's Blog</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.147.5</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://code.jquery.com/jquery-3.7.0.slim.min.js integrity=sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script><script src=https://bzoltan1.github.io/js/main.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://bzoltan1.github.io/js/load-photoswipe.js></script></body></html>